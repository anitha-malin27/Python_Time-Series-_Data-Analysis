{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time Series Data Manipulation using Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date       Open       High        Low      Close  Adj Close  Volume\n",
      "0   12/1/2003  45.709000  45.728001  45.449001  45.480000  45.480000     0.0\n",
      "1   12/8/2003  45.474998  45.507999  45.352001  45.451000  45.451000     0.0\n",
      "2  12/15/2003  45.450001  45.500000  45.332001  45.455002  45.455002     0.0\n",
      "3  12/22/2003  45.417000  45.549000  45.296001  45.507999  45.507999     0.0\n",
      "4  12/29/2003  45.439999  45.645000  45.421001  45.560001  45.560001     0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "time_series_data = pd.read_csv(r\"C:\\Data Analysis\\INR-USD.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(time_series_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of columns like ‘Date’, ‘Open’, ‘High’, ‘Low’, ‘Close’, ‘Adj Close’, and ‘Volume’. These columns are typical in financial time series datasets, where:\n",
    "Date: Represents the time at which the data was recorded.\n",
    "Open: The price at the beginning of the trading period.\n",
    "High: The highest price during the trading period.\n",
    "Low: The lowest price during the trading period.\n",
    "Close: The price at the end of the trading period.\n",
    "Adj Close: The closing price after adjustments for all applicable splits and dividend distributions.\n",
    "Volume: Trade Volume.\n",
    "The next step is to ensure that the ‘Date’ column is correctly recognized as a date. It is crucial for time series analysis, as it allows the data to be manipulated and queried based on time. Let’s parse the ‘Date’ column and set it as the index of the DataFrame:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Open       High        Low      Close  Adj Close  Volume\n",
      "Date                                                                     \n",
      "2003-12-01  45.709000  45.728001  45.449001  45.480000  45.480000     0.0\n",
      "2003-12-08  45.474998  45.507999  45.352001  45.451000  45.451000     0.0\n",
      "2003-12-15  45.450001  45.500000  45.332001  45.455002  45.455002     0.0\n",
      "2003-12-22  45.417000  45.549000  45.296001  45.507999  45.507999     0.0\n",
      "2003-12-29  45.439999  45.645000  45.421001  45.560001  45.560001     0.0\n"
     ]
    }
   ],
   "source": [
    "# Parsing the 'Date' column and setting it as the index\n",
    "time_series_data['Date'] = pd.to_datetime(time_series_data['Date'])\n",
    "time_series_data.set_index('Date', inplace=True)\n",
    "\n",
    "# Display the DataFrame with the parsed dates\n",
    "print(time_series_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the ‘Date’ column is correctly parsed and set as the index, the next step is to inspect the data for any missing or anomalous values (using descriptive statistics):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open         3\n",
      "High         3\n",
      "Low          3\n",
      "Close        3\n",
      "Adj Close    3\n",
      "Volume       3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "missing_values = time_series_data.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Open         High          Low        Close    Adj Close  Volume\n",
      "count  1013.000000  1013.000000  1013.000000  1013.000000  1013.000000  1013.0\n",
      "mean     58.035208    58.506681    57.654706    58.056509    58.056509     0.0\n",
      "std      12.614635    12.716632    12.565279    12.657407    12.657407     0.0\n",
      "min      38.995998    39.334999    38.979000    39.044998    39.044998     0.0\n",
      "25%      45.508999    45.775002    45.231998    45.498001    45.498001     0.0\n",
      "50%      59.702999    60.342999    59.209999    59.840000    59.840000     0.0\n",
      "75%      68.508499    69.099998    68.250000    68.538002    68.538002     0.0\n",
      "max      82.917999    83.386002    82.563004    82.932999    82.932999     0.0\n"
     ]
    }
   ],
   "source": [
    "basic_statistics = time_series_data.describe()\n",
    "print(basic_statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three missing values in each of the columns except for the ‘Date’ column. The descriptive statistics do not immediately suggest the presence of extreme anomalies or outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Handling missing values by imputing with the mean\n",
    "time_series_data_filled = time_series_data.fillna(time_series_data.mean())\n",
    "\n",
    "# Verify that there are no more missing values\n",
    "missing_values_after = time_series_data_filled.isnull().sum()\n",
    "\n",
    "print(missing_values_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The missing values have been successfully filled with the mean of their respective columns, and there are no more missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Open       High        Low     Close  Adj Close  Volume\n",
      "Date                                                                    \n",
      "2003-12-31  45.498200  45.586000  45.370001  45.49080   45.49080     0.0\n",
      "2004-01-31  45.365999  45.433750  45.172999  45.23675   45.23675     0.0\n",
      "2004-02-29  45.167251  45.285999  45.106251  45.27450   45.27450     0.0\n",
      "2004-03-31  45.026801  45.073800  44.558600  44.75880   44.75880     0.0\n",
      "2004-04-30  43.767750  44.049250  43.630000  43.90800   43.90800     0.0\n"
     ]
    }
   ],
   "source": [
    "# Resampling the data from weekly to monthly frequency\n",
    "monthly_resampled_data = time_series_data_filled.resample('M').mean()\n",
    "\n",
    "print(monthly_resampled_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Year  Month  Quarter  WeekOfYear  Close_Lag1  Close_Lag2  \\\n",
      "Date                                                                   \n",
      "2003-12-31  2003     12        4           1         NaN         NaN   \n",
      "2004-01-31  2004      1        1           5    45.49080         NaN   \n",
      "2004-02-29  2004      2        1           9    45.23675    45.49080   \n",
      "2004-03-31  2004      3        1          14    45.27450    45.23675   \n",
      "2004-04-30  2004      4        2          18    44.75880    45.27450   \n",
      "\n",
      "            Close_Rolling_Mean  Close_Rolling_Std  \n",
      "Date                                               \n",
      "2003-12-31                 NaN                NaN  \n",
      "2004-01-31                 NaN                NaN  \n",
      "2004-02-29           45.334017           0.137084  \n",
      "2004-03-31           45.090017           0.287462  \n",
      "2004-04-30           44.647100           0.690064  \n"
     ]
    }
   ],
   "source": [
    "# Extracting date-time features\n",
    "monthly_resampled_data['Year'] = monthly_resampled_data.index.year\n",
    "monthly_resampled_data['Month'] = monthly_resampled_data.index.month\n",
    "monthly_resampled_data['Quarter'] = monthly_resampled_data.index.quarter\n",
    "monthly_resampled_data['WeekOfYear'] = monthly_resampled_data.index.isocalendar().week\n",
    "\n",
    "# Creating lag features for 'Close' price\n",
    "monthly_resampled_data['Close_Lag1'] = monthly_resampled_data['Close'].shift(1)\n",
    "monthly_resampled_data['Close_Lag2'] = monthly_resampled_data['Close'].shift(2)\n",
    "\n",
    "# Rolling window statistics for 'Close' price (using a window of 3 months)\n",
    "monthly_resampled_data['Close_Rolling_Mean'] = monthly_resampled_data['Close'].rolling(window=3).mean()\n",
    "monthly_resampled_data['Close_Rolling_Std'] = monthly_resampled_data['Close'].rolling(window=3).std()\n",
    "\n",
    "# Displaying the DataFrame with the new features\n",
    "print(monthly_resampled_data[['Year', 'Month', 'Quarter', 'WeekOfYear', \n",
    "                              'Close_Lag1', 'Close_Lag2', \n",
    "                              'Close_Rolling_Mean', 'Close_Rolling_Std']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary\n",
    "Manipulating time series data involves several steps including loading the data, parsing time information, handling missing values, resampling for different time periods, and potentially transforming or aggregating the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
